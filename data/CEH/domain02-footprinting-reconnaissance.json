[
  {
    "id": 6,
    "pdf_number": 7,
    "question": "Gerard, a disgruntled ex-employee of Sunglass IT Solutions, targets this organization to perform sophisticated attacks and bring down its reputation in the market. To launch the attacks process, he performed DNS footprinting to gather information about DNS servers and to identify the hosts connected in the target network. He used an automated tool that can retrieve information about DNS zone data including DNS domain names, computer names, IP addresses, DNS records, and network Whois records. He further exploited this information to launch other sophisticated attacks. What is the tool employed by Gerard in the above scenario?",
    "options": [
      "Towelroot",
      "Knative",
      "zANTI",
      "Bluto"
    ],
    "correct": [
      3
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: Bluto**\n\n**Bluto** is an automated DNS reconnaissance tool for comprehensive footprinting:\n\n• **Purpose**: DNS footprinting and information gathering\n• **Key Features**: Retrieves DNS zone data, domain names, computer names, IP addresses, DNS records (A, AAAA, MX, NS, SOA, TXT), and Whois information\n• **Automation**: Combines multiple DNS enumeration techniques\n• **Use Case**: Reconnaissance phase for penetration testing\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **Towelroot**: Android rooting exploit tool - NOT for DNS footprinting\n• **Knative**: Kubernetes-based serverless platform - NOT a security tool\n• **zANTI**: Mobile penetration testing toolkit - NOT specifically for DNS\n\n**KEY CONCEPTS:**\n• DNS Footprinting: Gathering DNS server and host information\n• DNS Zone Transfer: Extracting complete DNS zone data\n• Whois Lookup: Domain registration and network information\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > DNS Footprinting Tools"
  },
  {
    "id": 8,
    "pdf_number": 9,
    "question": "Which of the following Google advanced search operators helps an attacker in gathering information about websites that are similar to a specified target URL?",
    "options": [
      "[inurl:]",
      "[info:]",
      "[site:]",
      "[related:]"
    ],
    "correct": [
      3
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: [related:]**\n\n**Google Advanced Search Operator 'related:'** finds websites similar to a target URL:\n\n• **Syntax**: related:example.com\n• **Function**: Returns websites Google considers similar or related to specified URL\n• **Use Case**: Discovering competitor websites, similar businesses, related organizations\n• **OSINT Value**: Identifies target's ecosystem, partners, subsidiaries, competitors\n• **Example**: related:microsoft.com shows Apple, Google, IBM, Oracle, etc.\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **[inurl:]**: Searches for keywords IN the URL string - NOT for similar sites. Example: inurl:admin finds URLs containing admin\n• **[info:]**: Shows Google cached page info, similar pages, links - More comprehensive than just similar sites\n• **[site:]**: Restricts search to specific domain/site - NOT for finding similar sites. Example: site:microsoft.com searches only Microsoft's site\n\n**KEY CONCEPTS:**\n• Google Dorks/Advanced Operators\n• Competitive Intelligence\n• OSINT Reconnaissance\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Search Engine Footprinting > Google Advanced Search Operators"
  },
  {
    "id": 14,
    "pdf_number": 15,
    "question": "Taylor, a security professional, uses a tool to monitor her company's website, analyze the website's traffic, and track the geographical location of the users visiting the company's website. Which of the following tools did Taylor employ in the above scenario?",
    "options": [
      "Webroot",
      "Web-Stat",
      "WebSite-Watcher",
      "WAFW00F"
    ],
    "correct": [
      1
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: Web-Stat**\n\n**Web-Stat** is a website monitoring and analytics tool for tracking traffic and visitor geolocation:\n\n• **Purpose**: Website traffic analysis and visitor monitoring\n• **Key Features**: Real-time visitor monitoring, geographical location tracking (GeoIP), traffic analysis (pages, referrers, keywords), browser/OS detection, visitor path tracking\n• **Use Case**: Website intelligence, competitive analysis, footprinting\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **Webroot**: Antivirus and endpoint protection software - NOT website analytics\n• **WebSite-Watcher**: Monitors website changes and updates - NOT traffic analysis or geo-tracking\n• **WAFW00F**: Web Application Firewall (WAF) detection tool - NOT website analytics\n\n**KEY CONCEPTS:**\n• Website Footprinting: Gathering intelligence from web analytics\n• GeoIP Tracking: Identifying visitor geographical locations\n• Traffic Analysis: Understanding website visitor patterns\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Website Footprinting > Website Monitoring Tools"
  },
  {
    "id": 15,
    "pdf_number": 16,
    "question": "Becky has been hired by a client from Dubai to perform a penetration test against one of their remote offices. Working from her location in Columbus, Ohio, Becky runs her usual reconnaissance scans to obtain basic information about their network. When analyzing the results of her Whois search, Becky notices that the IP was allocated to a location in Le Havre, France. Which regional Internet registry should Becky go to for detailed information?",
    "options": [
      "ARIN",
      "LACNIC",
      "APNIC",
      "RIPE"
    ],
    "correct": [
      3
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: RIPE**\n\n**RIPE NCC** (Reseaux IP Europeens Network Coordination Centre) is the Regional Internet Registry for Europe:\n\n• **Geographic Coverage**: Europe, Middle East, parts of Central Asia\n• **Le Havre, France**: Located in Europe, therefore falls under RIPE jurisdiction\n• **Function**: Allocates and registers IP addresses, AS numbers for European region\n• **Whois Database**: Provides detailed IP allocation, network information, contact details\n• **Use Case**: Footprinting European networks, finding network ownership details\n\n**5 Regional Internet Registries (RIRs):**\n1. ARIN - North America (USA, Canada)\n2. RIPE - Europe, Middle East (CORRECT)\n3. APNIC - Asia-Pacific\n4. LACNIC - Latin America, Caribbean\n5. AFRINIC - Africa\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **ARIN**: Covers North America. Becky is FROM Ohio but target IP is in FRANCE\n• **LACNIC**: Latin America/Caribbean - NOT Europe\n• **APNIC**: Asia-Pacific region - Dubai client is irrelevant, IP is in France\n\n**KEY CONCEPTS:**\n• Regional Internet Registries (RIRs)\n• IP Allocation Geography\n• Whois Footprinting\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Whois Footprinting > Regional Internet Registries"
  },
  {
    "id": 34,
    "pdf_number": 35,
    "question": "Scenario: Joe turns on his home computer to access personal online banking. When he enters the URL www.bank.com, the website is displayed, but it prompts him to re-enter his credentials as if he has never visited the site before. When he examines the website URL closer, he finds that the site is not secure and the web address appears different. What type of attack he is experiencing?",
    "options": [
      "DHCP spoofing",
      "DoS attack",
      "ARP cache poisoning",
      "DNS hijacking"
    ],
    "correct": [
      3
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: DNS hijacking**\n\n**DNS hijacking** (DNS redirection) redirects DNS queries to malicious servers serving fake websites:\n\n• **Key Indicators**: URL entered correctly (www.bank.com), different web address displayed, site not secure, credentials requested again\n• **How it works**: Attacker modifies DNS records or compromises DNS server, redirecting legitimate domain to malicious IP\n• **Goal**: Steal credentials, financial information, install malware\n• **User Impact**: Thinks accessing real site but actually on attacker-controlled phishing site\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **DHCP spoofing**: Rogue DHCP server assigns malicious network configs (DNS, gateway). While related, question describes DNS-specific redirect\n• **DoS attack**: Makes service unavailable through resource exhaustion. Joe CAN access website (wrong one)\n• **ARP cache poisoning**: Man-in-the-middle on local network intercepting traffic. Typically same site URL, not different address\n\n**KEY CONCEPTS:**\n• DNS Hijacking: Redirecting DNS queries to malicious servers\n• Pharming: Large-scale DNS hijacking\n• Phishing: Fake websites stealing credentials\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > DNS Attacks"
  },
  {
    "id": 49,
    "pdf_number": 52,
    "question": "Clark, a professional hacker, was hired by an organization to gather sensitive information about its competitors surreptitiously. Clark gathers the server IP address of the target organization using Whois footprinting. Further, he entered the server IP address as an input to an online tool to retrieve information such as the network range of the target organization and to identify the network topology and operating system used in the network. What is the online tool employed by Clark in the above scenario?",
    "options": [
      "DuckDuckGo",
      "AOL",
      "ARIN",
      "Baidu"
    ],
    "correct": [
      2
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: ARIN**\n\n**ARIN** (American Registry for Internet Numbers) provides network information lookup from IP addresses:\n\n• **Purpose**: Regional Internet Registry (RIR) database lookup tool\n• **Input**: IP address or network range\n• **Output**: Network range (CIDR), organization name, network topology details, AS numbers, contact information, sometimes OS fingerprinting\n• **Use Case**: Network footprinting, identifying network ownership and structure\n• **Online Access**: whois.arin.net provides web-based IP lookup\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **DuckDuckGo**: Privacy-focused search engine - NOT an IP/network lookup tool. Searches web content, not IP databases\n• **AOL**: Internet service provider and web portal - NOT a specialized network information tool\n• **Baidu**: Chinese search engine - NOT an IP/network lookup tool. Similar to Google, searches web content\n\n**KEY CONCEPTS:**\n• Whois Lookup: Domain and IP registration information\n• Network Footprinting: Identifying network infrastructure\n• RIR Databases: ARIN, RIPE, APNIC, LACNIC, AFRINIC\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Whois Footprinting > ARIN Lookup"
  },
  {
    "id": 70,
    "pdf_number": 73,
    "question": "Wilson, a professional hacker, targets an organization for financial benefit and plans to compromise its systems by sending malicious emails. For this purpose, he uses a tool to track the emails of the target and extracts information such as sender identities, mail servers, sender IP addresses, and sender locations from different public sources. He also checks if an email address was leaked using the haveibeenpwned.com API. Which of the following tools is used by Wilson in the above scenario?",
    "options": [
      "Factiva",
      "ZoomInfo",
      "Netcraft",
      "Infoga"
    ],
    "correct": [
      3
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: Infoga**\n\n**Infoga** is an email information gathering tool for OSINT and footprinting:\n\n• **Purpose**: Email footprinting and intelligence gathering\n• **Key Features**: Extracts sender identities, mail servers (MX records), sender IP addresses, sender geolocation from public sources\n• **haveibeenpwned.com API**: Checks if email addresses were leaked in data breaches\n• **Data Sources**: Search engines, Shodan, PGP key servers, social media\n• **Use Case**: Social engineering prep, phishing campaigns, OSINT investigations\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **Factiva**: Business news and information database - NOT email tracking tool\n• **ZoomInfo**: Business contact database for sales/marketing - NOT email footprinting tool with breach checking\n• **Netcraft**: Web server fingerprinting and website monitoring - NOT email tracking\n\n**KEY CONCEPTS:**\n• Email Footprinting: Gathering email-related intelligence\n• OSINT: Open Source Intelligence gathering\n• Data Breach Monitoring: Checking leaked credentials\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Email Footprinting > Email Tracking Tools"
  },
  {
    "id": 93,
    "pdf_number": 97,
    "question": "What would be the fastest way to perform content enumeration on a given web server by using the Gobuster tool?",
    "options": [
      "Performing content enumeration using the bruteforce mode and 10 threads",
      "Performing content enumeration using the bruteforce mode and random file extensions",
      "Skipping SSL certificate verification",
      "Performing content enumeration using a wordlist"
    ],
    "correct": [
      3
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: Performing content enumeration using a wordlist**\n\n**Wordlist mode** is the FASTEST method for Gobuster content enumeration:\n\n• **Why Fastest**: Wordlists contain known/common directory and file names, drastically reducing search space\n• **Efficiency**: Tests only probable paths instead of all possible combinations\n• **Command**: gobuster dir -u http://target.com -w wordlist.txt\n• **Popular Wordlists**: SecLists (directory-list-2.3-medium.txt), common.txt, raft-large-directories.txt\n• **Speed**: Thousands of requests per second with proper threading\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **Bruteforce mode with 10 threads**: MUCH slower - tests all character combinations. Even with threading, exponentially more requests than wordlist\n• **Bruteforce with random extensions**: Still bruteforce - extremely slow. Random extensions don't help speed\n• **Skipping SSL verification**: Security setting, NOT speed optimization. Marginally faster but not the primary speed factor\n\n**KEY CONCEPTS:**\n• Content Enumeration: Discovering hidden directories and files\n• Wordlist vs Bruteforce: Known names vs all combinations\n• Gobuster: Fast directory/file bruteforcing tool\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Website Footprinting > Directory Enumeration"
  },
  {
    "id": 96,
    "pdf_number": 100,
    "question": "Emily, an extrovert obsessed with social media, posts a large amount of private information, photographs, and location tags of recently visited places. Realizing this, James, a professional hacker, targets Emily and her acquaintances, conducts a location search to detect their geolocation by using an automated tool, and gathers information to perform other sophisticated attacks. What is the tool employed by James in the above scenario?",
    "options": [
      "ophcrack",
      "VisualRoute",
      "Hootsuite",
      "HULK"
    ],
    "correct": [
      2
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: Hootsuite**\n\n**Hootsuite** is a social media management and monitoring platform with geolocation intelligence capabilities:\n\n**PRIMARY FUNCTIONALITY:**\n• **Platform**: Multi-social network management dashboard\n• **Supported Networks**: Twitter, Facebook, Instagram, LinkedIn, YouTube, Pinterest, TikTok\n• **Core Features**: Post scheduling, engagement tracking, analytics, team collaboration\n• **OSINT Application**: Social media monitoring and geolocation tracking for intelligence gathering\n\n**GEOLOCATION TRACKING FEATURES:**\n• **Location Tags**: Monitors posts with embedded GPS coordinates\n• **Geotagged Content**: Analyzes photos/posts tagged with specific locations\n• **Location-Based Monitoring**: Creates location-specific social media streams\n• **Geographic Analytics**: Tracks where target's followers/engagement originates\n• **Check-in Detection**: Identifies when targets check in at locations (Facebook, Instagram)\n• **Historical Location Data**: Builds timeline of visited places from social media history\n\n**JAMES'S ATTACK SCENARIO:**\n1. Emily posts photos with location tags (restaurants, tourist spots, home area)\n2. James uses Hootsuite to aggregate Emily's social media activity\n3. Location monitoring reveals patterns (home, work, frequented places)\n4. Gathers intelligence on Emily's routine and physical locations\n5. Extends to her acquaintances through social connections\n6. Uses data for targeted attacks (physical approach, contextual social engineering)\n\n**INFORMATION GATHERED:**\n• Current and historical locations\n• Travel patterns and routine\n• Home/work addresses (inferred from repeated locations)\n• Social connections and their locations\n• Interests based on venues visited\n• Time patterns (when at specific locations)\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **ophcrack**: Windows password cracking tool using rainbow tables - analyzes SAM database hashes. COMPLETELY unrelated to social media or geolocation\n• **VisualRoute**: Network traceroute and packet tracing tool - shows network path and hop locations. Tracks NETWORK infrastructure, not people/social media\n• **HULK (HTTP Unbearable Load King)**: Denial-of-Service (DoS) attack tool - floods web servers with requests. ATTACK tool, not reconnaissance/OSINT\n\n**SOCIAL MEDIA OSINT WORKFLOW:**\n1. **Discovery**: Find target's social media accounts\n2. **Monitoring**: Use Hootsuite to aggregate posts\n3. **Analysis**: Extract geolocation, patterns, connections\n4. **Intelligence**: Build profile for social engineering attacks\n\n**KEY CONCEPTS:**\n• SOCMINT (Social Media Intelligence): Intelligence gathering from social platforms\n• Geolocation Tracking: Monitoring physical locations from digital footprints\n• Social Media Monitoring: Automated tracking of posts and activities\n• OSINT: Open Source Intelligence from publicly available information\n• Privacy Risks: Oversharing location data enables stalking/targeting\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Social Media Footprinting > Social Media Monitoring Tools > Hootsuite"
  },
  {
    "id": 104,
    "pdf_number": 108,
    "question": "Hackers often raise the trust level of a phishing message by modeling the email to look similar to the internal email used by the target company. This includes using logos, formatting, and names of the target company. The phishing message will often use the name of the company CEO, President, or Managers. The time a hacker spends performing research to locate this information about a company is known as?",
    "options": [
      "Exploration",
      "Investigation",
      "Reconnaissance",
      "Enumeration"
    ],
    "correct": [
      2
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: Reconnaissance**\n\n**Reconnaissance** is the information gathering phase before attacks:\n\n• **Definition**: Systematic collection of target intelligence before launching attacks\n• **Activities**: Researching company structure, employee names, email formats, logos, internal procedures, executive names\n• **Goal**: Gather information for social engineering attacks (phishing, pretexting)\n• **Duration**: Days to weeks of passive/active intelligence gathering\n• **CEH Methodology**: First phase in ethical hacking\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **Exploration**: Not a CEH term - too generic\n• **Investigation**: Post-incident analysis, NOT pre-attack intelligence gathering\n• **Enumeration**: Active probing to extract specific data (usernames, shares, services) AFTER recon\n\n**KEY CONCEPTS:**\n• Reconnaissance: Passive and active information gathering\n• Social Engineering Prep: Using gathered intel for attacks\n• OSINT: Open Source Intelligence\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Footprinting Methodology"
  },
  {
    "id": 113,
    "pdf_number": 117,
    "question": "Juliet, a security researcher in an organization, was tasked with checking for the authenticity of images to be used in the organization's magazines. She used these images as a search query and tracked the original source and details of the images, which included photographs, profile pictures, and memes. Which of the following footprinting techniques did Rachel use to finish her task?",
    "options": [
      "Google advanced search",
      "Meta search engines",
      "Reverse image search",
      "Advanced image search"
    ],
    "correct": [
      2
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: Reverse image search**\n\n**Reverse image search** allows searching using an image to find its source and related information:\n\n• **How it works**: Upload image or paste URL, search engine finds visually similar images and sources\n• **Tools**: Google Images (Search by image), TinEye, Yandex Images, Bing Visual Search\n• **Information Found**: Original source, similar images, different resolutions, websites using the image, metadata\n• **Use Case**: Verify image authenticity, find original source, detect stolen/fake images, OSINT investigations\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **Google advanced search**: Text-based search with operators - NOT image-based search\n• **Meta search engines**: Aggregate results from multiple search engines - NOT image-specific search\n• **Advanced image search**: Google feature for filtering image searches by size/color/type - NOT reverse search\n\n**KEY CONCEPTS:**\n• Reverse Image Search: Finding image sources using the image itself\n• Image Verification: Authenticating image origins\n• OSINT: Visual intelligence gathering\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Image Footprinting"
  },
  {
    "id": 119,
    "pdf_number": 123,
    "question": "Which file is a rich target to discover the structure of a website during web-server footprinting?",
    "options": [
      "domain.txt",
      "Robots.txt",
      "Document root",
      "index.html"
    ],
    "correct": [
      1
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: Robots.txt**\n\n**Robots.txt** reveals website structure and directories that site owners want hidden from search engines:\n\n• **Purpose**: Instructs web crawlers which pages/directories NOT to index\n• **Location**: Root directory (example.com/robots.txt)\n• **Information Revealed**: Disallowed directories (often sensitive: /admin, /private, /backup), sitemap location, user-agent rules\n• **Attacker Value**: Roadmap to hidden/sensitive areas, admin panels, backup files\n• **Always Public**: Accessible to anyone without authentication\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **domain.txt**: Not a standard web file - doesn't exist on most servers\n• **Document root**: Physical server directory location - NOT a file that reveals structure\n• **index.html**: Homepage file - Shows only public content, not hidden structure\n\n**KEY CONCEPTS:**\n• Robots.txt: Search engine instruction file\n• Directory Disclosure: Unintentional information leakage\n• Web Server Footprinting\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Website Footprinting > Robots.txt"
  },
  {
    "id": 141,
    "pdf_number": 145,
    "question": "As a Certified Ethical Hacker, you are conducting a footprinting and reconnaissance operation against a target organization. You discover a range of IP addresses associated with the target using the SecurityTrails tool. Now, you need to perform a reverse DNS lookup on these IP addresses to find the associated domain names, as well as determine the nameservers and mail exchange (MX) records. Which of the following DNSRecon commands would be most effective for this purpose?",
    "options": [
      "dnsrecon -r 192.168.1.0/24 -n nsl.example.com -t axfr",
      "dnsrecon -r 10.0.0.0/24 -n nsl.example.com -t zonewalk",
      "dnsrecon -r 162.241.216.0/24 -n nsl.example.com -t std",
      "dnsrecon -r 162.241.216.0/24 -d example.com -t brt"
    ],
    "correct": [
      2
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: dnsrecon -r 162.241.216.0/24 -n nsl.example.com -t std**\n\n**DNSRecon** is a powerful DNS enumeration tool - **-t std** performs comprehensive standard enumeration:\n\n**COMMAND BREAKDOWN:**\n• **dnsrecon**: DNS reconnaissance tool for information gathering\n• **-r 162.241.216.0/24**: Specifies IP range for reverse DNS lookup (CIDR notation)\n• **-n nsl.example.com**: Nameserver to query (uses specific DNS server instead of system default)\n• **-t std**: Enumeration type = STANDARD (most comprehensive basic scan)\n\n**WHAT -t std ENUMERATES:**\n• **A Records**: IPv4 address mappings (domain → IP)\n• **AAAA Records**: IPv6 address mappings\n• **NS Records**: Nameserver information (authoritative DNS servers)\n• **MX Records**: Mail exchange servers (email routing)\n• **SOA Records**: Start of Authority (zone information, admin contact)\n• **TXT Records**: Text records (SPF, DKIM, domain verification)\n• **PTR Records**: Reverse DNS lookups (IP → domain name) - KEY for this question\n\n**REVERSE DNS IMPORTANCE:**\n• Maps IP addresses back to domain names\n• Reveals internal naming conventions\n• Discovers additional subdomains and hosts\n• Validates IP ownership\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **-t axfr** (Zone Transfer): Attempts full DNS zone transfer from nameserver - only works if server misconfigured to allow unauthorized zone transfers. More aggressive, often blocked\n• **-t zonewalk** (DNSSEC Zone Walking): Exploits DNSSEC NSEC records to enumerate zone - requires DNSSEC implementation, specialized technique\n• **-t brt** (Brute Force): Dictionary attack to discover subdomains using wordlist - active enumeration, NOT reverse DNS lookup\n\n**DNSRecon ENUMERATION TYPES:**\n• std: Standard enumeration (A, AAAA, NS, MX, SOA, TXT, reverse DNS)\n• axfr: Zone transfer attempt\n• bing: Bing search for subdomains\n• yand: Yandex search for subdomains\n• zonewalk: DNSSEC zone walking\n• brt: Brute force subdomains\n\n**KEY CONCEPTS:**\n• DNS Enumeration: Gathering DNS infrastructure information\n• Reverse DNS Lookup: PTR records mapping IPs to domain names\n• Standard Enumeration: Comprehensive record type queries\n• Passive vs. Active: -t std is relatively passive, -t axfr/brt more active\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > DNS Footprinting > DNS Enumeration Tools > DNSRecon"
  },
  {
    "id": 157,
    "pdf_number": 161,
    "question": "An ethical hacker is conducting a controlled test to evaluate the security of a network against web-based attacks. The hacker begins the test by visiting the organization's public website and systematically exploring every page and functionality, collecting information about technologies, server configurations, and potential vulnerabilities. They also leverage browser plug-ins and extensions to capture data like HTTP headers, cookies, and hidden form fields. What is the term for this phase of the attack?",
    "options": [
      "Session hijacking",
      "Cross-site scripting",
      "Web server footprinting",
      "SQL injection"
    ],
    "correct": [
      2
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: Web server footprinting**\n\n**Web server footprinting** is the reconnaissance phase for gathering web server intelligence:\n\n• **Activities**: Systematically exploring website pages/functionality, collecting technology info, analyzing server configs\n• **Data Collected**: HTTP headers, cookies, hidden form fields, server software/versions, frameworks, CMS, plugins\n• **Tools**: Browser plugins (Wappalyzer, BuiltWith), developer tools, manual analysis\n• **Goal**: Map attack surface before exploitation\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **Session hijacking**: Attack technique stealing user sessions - NOT reconnaissance\n• **Cross-site scripting (XSS)**: Injection attack - NOT information gathering\n• **SQL injection**: Database attack - NOT reconnaissance phase\n\n**KEY CONCEPTS:**\n• Web Server Footprinting: Reconnaissance phase\n• Information Gathering: Pre-attack intelligence\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Website Footprinting"
  },
  {
    "id": 163,
    "pdf_number": 167,
    "question": "A certified ethical hacker is carrying out an email footprinting exercise on a targeted organization using eMailTrackerPro. They want to map out detailed information about the recipient's activities after receiving the email. Which among the following pieces of information would NOT be directly obtained from eMailTrackerPro during this exercise?",
    "options": [
      "Geolocation of the recipient",
      "Type of device used to open the email",
      "The email accounts related to the domain of the organization",
      "The time recipient spent reading the email"
    ],
    "correct": [
      2
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: The email accounts related to the domain of the organization**\n\n**eMailTrackerPro** is an EMAIL TRACKING tool for recipient activity monitoring - NOT email discovery:\n\n**PURPOSE & FUNCTIONALITY:**\n• **Primary Use**: Track individual email recipient's activities after receiving your email\n• **Technology**: Embeds invisible tracking pixel (1x1 image) in HTML emails\n• **Data Collection**: Monitors when/where/how recipient interacts with email\n• **Scope**: Single recipient behavior analysis - NOT domain-wide email enumeration\n\n**WHAT eMailTrackerPro DOES TRACK:**\n\n1. **Geolocation of Recipient**: YES\n   - IP address geolocation\n   - Country, region, city information\n   - ISP details\n   - Approximate physical location\n\n2. **Device Type**: YES\n   - User-agent string analysis\n   - Desktop vs. Mobile\n   - Operating system (Windows, macOS, iOS, Android)\n   - Email client (Outlook, Gmail, Apple Mail)\n\n3. **Time Spent Reading**: YES\n   - Email open time/date\n   - Read duration (if tracking pixel remains loaded)\n   - Multiple opens detection\n   - Read confirmation\n\n4. **Email Accounts Related to Domain**: NO - THIS IS THE ANSWER\n   - eMailTrackerPro tracks ONE recipient's behavior\n   - Does NOT discover other email accounts\n   - Does NOT enumerate @organization.com addresses\n   - NOT an OSINT/email harvesting tool\n\n**EMAIL ENUMERATION vs. EMAIL TRACKING:**\n• **Email Enumeration**: Finding/discovering email addresses (tools: theHarvester, Hunter.io, Infoga)\n• **Email Tracking**: Monitoring recipient behavior AFTER sending (tools: eMailTrackerPro, Mailtrack, ReadNotify)\n\n**FOR EMAIL ACCOUNT DISCOVERY, USE:**\n• theHarvester: OSINT email collection from public sources\n• Infoga: Email footprinting with haveibeenpwned integration\n• Hunter.io: Domain email pattern discovery\n• Google Dorking: site:linkedin.com \"@target.com\"\n• WHOIS records: Technical/admin contact emails\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Email Footprinting > Email Tracking Tools > eMailTrackerPro"
  },
  {
    "id": 176,
    "pdf_number": 180,
    "question": "During a reconnaissance mission, an ethical hacker uses Maltego, a popular footprinting tool, to collect information about a target organization. The information includes the target's Internet infrastructure details (domains, DNS names, Netblocks, IP address information). The hacker decides to use social engineering techniques to gain further information. Which of the following would be the least likely method of social engineering to yield beneficial information based on the data collected?",
    "options": [
      "Dumpster diving in the target company's trash bins for valuable printouts",
      "Impersonating an ISP technical support agent to trick the target into providing further network details",
      "Shoulder surfing to observe sensitive credentials input on the target's computers",
      "Eavesdropping on internal corporate conversations to understand key topics"
    ],
    "correct": [
      2
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: Shoulder surfing to observe sensitive credentials input on the target's computers**\n\nNeste cenário, o atacante já usou o **Maltego** para mapear a **infraestrutura de Internet** do alvo (domínios, DNS names, netblocks, IPs). A pergunta é: qual técnica de engenharia social é **menos provável** tirar partido dessa informação prévia.\n\n• **Maltego foca-se em OSINT de infraestrutura**: relações entre domínios, hosts, IPs, ASNs, DNS records, etc.\n• A informação recolhida é sobretudo **técnica e de rede**, não sobre comportamentos físicos dos utilizadores.\n• **Shoulder surfing** é um ataque físico direto (observar teclado/ecrã) que funciona praticamente da mesma forma **com ou sem** o mapa de infraestrutura obtido pelo Maltego. O output do Maltego quase não acrescenta valor a esta técnica.\n\n**PORQUE AS OUTRAS SÃO MAIS PROVÁVEIS DE BENEFICIAR DO MALTEGO:**\n\n• **A. Dumpster diving**: o mapa de domínios/IPs ajuda a reconhecer e valorizar documentos encontrados no lixo (diagramas de rede, listas de hosts, credenciais associadas a sistemas específicos, etc.).\n\n• **B. Impersonar suporte técnico do ISP**: conhecer domínios, blocos IP e detalhes de infraestrutura facilita um pretexto credível (referir netblocks, gateways, ranges específicos, etc.), alinhando-se bem com o tipo de dados que o Maltego fornece.\n\n• **D. Eavesdropping em conversas internas**: sabendo já quais são sistemas críticos, domínios e serviços, o atacante sabe **que tópicos técnicos** procurar nas conversas e o contexto em que esses nomes aparecem, tirando mais partido da escuta.\n\n**CONCLUSÃO:**\nEntre as quatro opções, **shoulder surfing** é a que **menos depende** ou beneficia da informação de infraestrutura recolhida pelo Maltego, sendo portanto a **menos provável** de produzir informação adicional relevante \"com base nos dados recolhidos\".\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Footprinting Tools (Maltego) & Social Engineering"
  },
  {
    "id": 182,
    "pdf_number": 186,
    "question": "In your capacity as a penetration tester, you are trying to gather information about a target company's email addresses for a social engineering campaign. You decided to employ a footprinting tool that interacts with various search engines, servers, and databases to collect data. Which tool would you most likely use for this task and what information can it provide?",
    "options": [
      "theHarvester",
      "Maltego",
      "Recon-ng",
      "Nmap"
    ],
    "correct": [
      0
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: theHarvester - Collects emails, subdomains, hosts, employee names, open ports and banners from different public sources**\n\n**theHarvester** is the PRIMARY tool for automated email address collection and OSINT:\n\n• **Purpose**: Passive information gathering through public sources for email addresses and related data\n• **Data Sources**: Google, Bing, PGP key servers, LinkedIn, Twitter, Shodan, Baidu, Yahoo, Netcraft, VirusTotal, ThreatCrowd, CRTSH, DNSDumpster\n• **Information Collected**:\n  - Email addresses (primary target)\n  - Subdomains and hosts\n  - Employee names and job titles\n  - Open ports and service banners (via Shodan integration)\n  - IP addresses\n  - URLs\n\n**COMMAND EXAMPLES:**\n• Basic: theharvester -d target.com -b google\n• Multiple sources: theharvester -d target.com -b google,bing,linkedin\n• With output: theharvester -d target.com -b all -f output.html\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **Maltego**: Visual link analysis tool - displays relationships between entities. More comprehensive but NOT specifically designed for email harvesting. Requires manual transforms\n• **Recon-ng**: Full reconnaissance framework with modules - powerful but requires more setup and configuration than theHarvester's focused approach\n• **Nmap**: Network scanner for hosts and services discovery - does NOT gather email addresses or OSINT from public sources\n\n**KEY CONCEPTS:**\n• Email Footprinting: Gathering email addresses for social engineering and phishing campaigns\n• OSINT (Open Source Intelligence): Collecting information from publicly available sources\n• Passive Reconnaissance: Gathering intelligence without directly interacting with target\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Email Footprinting > Email Tracking Tools > theHarvester"
  },
  {
    "id": 219,
    "pdf_number": 223,
    "question": "A Certified Ethical Hacker is attempting to gather information about a target organization's network structure through network footprinting. During the operation, they encounter ICMP blocking by the target system's firewall. The hacker wants to ascertain the path that packets take to the host system from a source, using an alternative protocol. Which of the following actions should the hacker consider next?",
    "options": [
      "Use UDP Traceroute in the Linux operating system by executing the 'traceroute' command with the destination IP or domain name.",
      "Use the ICMP Traceroute on the Windows operating system as it is the default utility.",
      "Use the ARIN Whois database search tool to find the network range of the target network.",
      "Utilize the Path Analyzer Pro to trace the route from the source to the destination target systems."
    ],
    "correct": [
      0
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: Use UDP Traceroute in the Linux operating system by executing the 'traceroute' command**\n\n**UDP Traceroute** bypasses ICMP blocking to trace network paths:\n\n• **Problem**: Target firewall blocks ICMP Echo Request/Reply packets, making traditional traceroute ineffective\n• **Solution**: UDP Traceroute uses UDP packets on high ports (default 33434-33534) instead of ICMP\n• **Why It Works**: Many firewalls block ICMP for security but allow UDP traffic for legitimate services (DNS, VoIP, etc.)\n\n**LINUX TRACEROUTE (UDP by default):**\n• Command: traceroute target.com or traceroute 192.168.1.1\n• Method: Sends UDP packets with incrementing TTL values\n• Ports: Uses destination ports starting at 33434, incrementing for each probe\n• Output: Shows each hop's IP address and response time\n\n**WINDOWS TRACERT (ICMP):**\n• Command: tracert target.com\n• Method: Uses ICMP Echo Request (like ping)\n• Problem: WILL FAIL if ICMP is blocked by firewall\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **ICMP Traceroute on Windows**: This is the DEFAULT that's ALREADY BLOCKED - won't work as alternative\n• **ARIN Whois database**: Provides network registration info (IP ranges, ownership) - does NOT trace packet paths\n• **Path Analyzer Pro**: Windows GUI tool that primarily uses ICMP - will face same blocking issue as tracert\n\n**ALTERNATIVE METHODS:**\n• TCP Traceroute: traceroute -T -p 80 target.com (uses TCP SYN packets)\n• tcptraceroute: Specialized tool for TCP-based tracing\n\n**KEY CONCEPTS:**\n• Traceroute: Network diagnostic tool mapping packet paths hop-by-hop\n• TTL (Time To Live): Packet header value decremented at each hop, triggers ICMP Time Exceeded when reaching zero\n• Protocol Alternatives: Using UDP/TCP when ICMP is blocked\n• Firewall Evasion: Bypassing ICMP blocks for network reconnaissance\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Network Footprinting > Traceroute Tools > UDP Traceroute"
  },
  {
    "id": 221,
    "pdf_number": 225,
    "question": "A penetration tester is tasked with gathering information about the subdomains of a target organization's website. The tester needs a versatile and efficient solution for the task. Which of the following options would be the most effective method to accomplish this goal?",
    "options": [
      "Analyzing LinkedIn profiles to find employees of the target company and their job titles",
      "Employing a tool like Sublist3r, which is designed to enumerate the subdomains of websites using OSINT",
      "Using a people search service, such as Spokeo or Intelius, to gather information about the employees of the target organization",
      "Utilizing the Harvester tool to extract email addresses related to the target domain using a search engine like Google or Bing"
    ],
    "correct": [
      1
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: Employing a tool like Sublist3r, which is designed to enumerate the subdomains of websites using OSINT**\n\n**Sublist3r** is THE specialized tool for fast, automated subdomain enumeration:\n\n• **Purpose**: OSINT-based subdomain discovery using passive reconnaissance\n• **Method**: Queries multiple search engines and services to find subdomains without directly scanning target\n• **Data Sources**: Google, Yahoo, Bing, Baidu, Ask, Netcraft, DNSdumpster, VirusTotal, ThreatCrowd, SSL Certificates, PassiveDNS\n• **Key Features**:\n  - Fast multi-threaded enumeration\n  - No direct DNS queries to target (passive)\n  - Integrates with Subbrute for bruteforce option\n  - Python-based, cross-platform\n\n**COMMAND EXAMPLES:**\n• Basic: sublist3r -d target.com\n• With output: sublist3r -d target.com -o output.txt\n• With bruteforce: sublist3r -d target.com -b\n• Multiple threads: sublist3r -d target.com -t 50\n\n**WHY SUBLIST3R IS MOST EFFECTIVE:**\n• Specifically designed for subdomain enumeration\n• Queries 10+ sources simultaneously\n• Fast and automated (no manual work)\n• Passive (doesn't alert target)\n• Easy to use with clear output\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **LinkedIn profile analysis**: Finds employee names/job titles - NOT subdomains. Different reconnaissance goal\n• **People search services (Spokeo/Intelius)**: Background checks on individuals - COMPLETELY unrelated to subdomain discovery\n• **The Harvester**: Primarily for EMAIL addresses, can find some subdomains as secondary data - NOT specialized for subdomain enumeration\n\n**SUBDOMAIN IMPORTANCE:**\n• Attack Surface Expansion: Subdomains often have weaker security (dev, staging, admin, vpn, mail)\n• Hidden Assets: Development servers, admin panels, internal tools\n• Vulnerability Discovery: Forgotten or unmonitored subdomains\n\n**KEY CONCEPTS:**\n• Subdomain Enumeration: Discovering all subdomains under a parent domain\n• OSINT: Open Source Intelligence from public sources\n• Passive Reconnaissance: Information gathering without direct target interaction\n• DNS Footprinting: Mapping organization's DNS infrastructure\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > DNS Footprinting > Subdomain Enumeration > Sublist3r"
  },
  {
    "id": 247,
    "pdf_number": 251,
    "question": "A penetration tester is performing the footprinting process and is reviewing publicly available information about an organization by using the Google search engine. Which of the following advanced operators would allow the pen tester to restrict the search to the organization's web domain?",
    "options": [
      "[allinurl:]",
      "[location:]",
      "[site:]",
      "[link:]"
    ],
    "correct": [
      2
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: [site:]**\n\n**site:** operator restricts Google search results to a specific domain or website:\n\n• **Syntax**: site:example.com [search terms]\n• **Function**: Returns ONLY results from the specified domain and its subdomains\n• **Primary Use**: Focused reconnaissance on target organization's web presence\n• **Scope Control**: Can narrow to specific subdomain (site:admin.example.com) or widen to entire domain (site:example.com)\n\n**FOOTPRINTING APPLICATIONS:**\n• **Content Discovery**: site:target.com filetype:pdf (find PDFs on target site)\n• **Credential Exposure**: site:target.com intext:\"password\" OR intext:\"username\"\n• **Technology Stack**: site:target.com inurl:admin OR inurl:login\n• **Subdomain Enum**: site:*.target.com -www (find all subdomains except www)\n• **Document Leakage**: site:target.com (confidential OR internal OR restricted)\n• **Employee Info**: site:linkedin.com \"employees at target.com\"\n\n**COMBINED OPERATOR EXAMPLES:**\n• site:target.com intitle:\"index of\"\n• site:target.com filetype:sql\n• site:target.com inurl:admin intitle:login\n• site:target.com ext:log OR ext:txt\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **[allinurl:]**: Searches for ALL specified words IN THE URL across entire web - does NOT restrict to organization's domain. Example: allinurl:admin login finds ANY site with both words in URL\n• **[location:]**: Geographic search filter - NOT a real Google operator. Google uses location-based search automatically or via region settings\n• **[link:]**: Finds pages LINKING TO a specific URL - doesn't restrict search TO that domain. Example: link:example.com finds external sites linking to example.com\n\n**KEY CONCEPTS:**\n• Google Dorking/Hacking: Using advanced operators to find sensitive information\n• site: Operator: Domain-specific search restriction\n• Footprinting Methodology: Systematic information gathering about target organization\n• OSINT Reconnaissance: Collecting publicly available intelligence\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Search Engines > Google Advanced Search Operators > site: Operator"
  },
  {
    "id": 278,
    "pdf_number": 282,
    "question": "When considering how an attacker may exploit a web server, what is web server footprinting?",
    "options": [
      "When an attacker creates a complete profile of the site's external links and file structures",
      "When an attacker uses a brute-force attack to crack a web-server password",
      "When an attacker implements a vulnerability scanner to identity weaknesses",
      "When an attacker gathers system-level data, including account details and server names"
    ],
    "correct": [
      3
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: When an attacker gathers system-level data, including account details and server names**\n\n**Web Server Footprinting** is reconnaissance phase gathering system-level intelligence:\n\n• **Definition**: Collecting information about web server infrastructure, configuration, and underlying systems BEFORE launching attacks\n• **Objective**: Map attack surface, identify technologies, discover potential entry points\n• **Phase**: Reconnaissance/Information Gathering (NOT active exploitation)\n\n**INFORMATION COLLECTED:**\n• **Server Details**: Web server software (Apache, IIS, Nginx), version numbers\n• **Operating System**: OS type and version (Linux, Windows Server)\n• **Account Information**: Admin usernames, email addresses, directory structures\n• **Server Names**: Hostname, DNS names, internal server names\n• **Network Information**: IP addresses, subnet information, connected systems\n• **Technologies**: Programming languages (PHP, ASP.NET), frameworks, CMS (WordPress, Joomla)\n• **Directory Structure**: Site architecture, hidden directories, backup files\n• **Configuration Files**: Exposed config files, robots.txt, sitemap.xml\n• **SSL/TLS Certificates**: Certificate details, domain names, organizational info\n\n**FOOTPRINTING TECHNIQUES:**\n• **HTTP Headers Analysis**: Server header reveals software/version\n• **Banner Grabbing**: Netcat, Telnet, nmap -sV to extract service banners\n• **robots.txt Examination**: Reveals site structure, hidden directories\n• **WHOIS Lookup**: Domain registration details\n• **DNS Interrogation**: DNS records, subdomains\n• **Google Dorking**: site:target.com intitle:\"index of\"\n• **Shodan Search**: Find exposed services and banners\n• **SSL Certificate Analysis**: Examine cert for subdomains, internal names\n• **Web Archives**: archive.org for historical site information\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **Complete profile of site's external links and file structures**: This is link analysis and site mapping - only ONE aspect of footprinting, not the complete definition\n• **Brute-force attack to crack web-server password**: This is ACTIVE ATTACK/exploitation phase - NOT reconnaissance footprinting\n• **Vulnerability scanner to identify weaknesses**: This is vulnerability assessment (like Nessus, OpenVAS) - MORE ACTIVE than footprinting, closer to scanning phase\n\n**FOOTPRINTING vs. OTHER PHASES:**\n• **Footprinting (Reconnaissance)**: Passive/semi-active information gathering\n• **Scanning**: Active probing for open ports, services\n• **Vulnerability Assessment**: Testing for specific vulnerabilities\n• **Exploitation**: Actively attacking identified weaknesses\n\n**KEY CONCEPTS:**\n• Web Server Footprinting: Reconnaissance of web infrastructure\n• System-Level Data: Technical details about servers and configurations\n• Passive Reconnaissance: Gathering without direct interaction\n• Attack Surface Mapping: Understanding all potential entry points\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Website Footprinting > Web Server Footprinting Techniques"
  },
  {
    "id": 280,
    "pdf_number": 284,
    "question": "James is working as an ethical hacker at Technix Solutions. The management ordered James to discover how vulnerable its network is towards footprinting attacks. James took the help of an open-source framework for performing automated reconnaissance activities. This framework helped James in gathering information using free tools and resources. What is the framework used by James to conduct footprinting and reconnaissance activities?",
    "options": [
      "OSINT framework",
      "WebSploit Framework",
      "Browser Exploitation Framework",
      "SpeedPhish Framework"
    ],
    "correct": [
      0
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: OSINT framework**\n\n**OSINT Framework** (osintframework.com) is the comprehensive, free, open-source collection of OSINT tools:\n\n• **Definition**: Web-based catalog/directory organizing hundreds of free OSINT (Open Source Intelligence) tools and resources\n• **Purpose**: Centralized hub for reconnaissance, providing organized access to information gathering tools\n• **Structure**: Tree-based categorization for easy navigation\n• **Accessibility**: Web interface, free to use, no installation required\n• **Updates**: Community-driven, regularly updated with new tools\n\n**TOOL CATEGORIES:**\n• **Username**: Search across social media and platforms\n• **Email Address**: Email verification, breach checking, profiling\n• **Domain Name**: WHOIS, DNS, subdomain enumeration\n• **IP Address**: Geolocation, reputation, ownership\n• **Social Networks**: Facebook, Twitter, LinkedIn, Instagram intelligence\n• **Search Engines**: Google dorking, specialized searches\n• **Instant Messaging**: Telegram, WhatsApp, Skype reconnaissance\n• **People Search**: Background checks, public records\n• **Phone Numbers**: Caller ID, location, carrier lookup\n• **Public Records**: Court records, business registrations\n• **Maps/Geolocation**: Satellite imagery, street view\n• **Documents**: Metadata extraction, document analysis\n• **Images**: Reverse image search, EXIF data\n• **Video**: YouTube analysis, video verification\n• **Dark Web**: Onion site search, dark web monitoring\n\n**JAMES'S USE CASE:**\n• Automated reconnaissance activities\n• Free tools and resources (no cost)\n• Discovering network vulnerabilities via footprinting\n• Comprehensive coverage across multiple intelligence domains\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **WebSploit Framework**: Web application exploitation framework for penetration testing - FOCUSED ON EXPLOITATION, not reconnaissance. Includes tools like directory bruteforce, SQLi\n• **Browser Exploitation Framework (BeEF)**: Focuses on web browser exploitation and client-side attacks - ACTIVE EXPLOITATION TOOL, not passive reconnaissance\n• **SpeedPhish Framework**: Phishing email campaign tool - SOCIAL ENGINEERING ATTACK TOOL, not general reconnaissance framework\n\n**KEY CONCEPTS:**\n• OSINT (Open Source Intelligence): Information gathering from publicly available sources\n• Footprinting: First phase of reconnaissance gathering target intelligence\n• Passive Reconnaissance: Collecting information without directly interacting with target\n• Framework: Organized collection of tools for systematic approach\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > OSINT Tools > OSINT Framework"
  },
  {
    "id": 286,
    "pdf_number": 290,
    "question": "In an attempt to damage the reputation of a competitor organization, Hailey, a professional hacker, gathers a list of employee and client email addresses and other related information by using various search engines, social networking sites, and web spidering tools. In this process, she also uses an automated tool to gather a list of words from the target website to further perform a brute-force attack on the previously gathered email addresses. What is the tool used by Hailey for gathering a list of words from the target website?",
    "options": [
      "CeWL",
      "Orbot",
      "Shadowsocks",
      "Psiphon"
    ],
    "correct": [
      0
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: CeWL**\n\n**CeWL (Custom Word List generator)** is a Ruby-based spider tool for creating targeted password wordlists:\n\n**PURPOSE & METHODOLOGY:**\n• **Primary Function**: Scrapes target website to extract words for custom wordlist generation\n• **Attack Application**: Creates context-specific dictionaries for password brute-force attacks\n• **Intelligence**: Harvests organization-specific terminology, product names, employee names, industry jargon\n• **Theory**: People often use familiar words as passwords (company names, products, locations)\n\n**HOW CeWL WORKS:**\n1. **Spider Website**: Crawls target website following links\n2. **Extract Words**: Parses HTML content for all words\n3. **Filter**: Removes common words, applies minimum word length\n4. **Generate List**: Creates dictionary file with unique words\n5. **Attack**: Uses wordlist for password attacks (dictionary/hybrid attacks)\n\n**COMMAND SYNTAX & OPTIONS:**\n• **Basic**: cewl http://target.com\n• **With depth**: cewl -d 2 http://target.com (crawl 2 levels deep)\n• **Minimum length**: cewl -m 5 http://target.com (5+ character words)\n• **Output file**: cewl -w wordlist.txt http://target.com\n• **Include meta**: cewl -meta http://target.com (extract metadata)\n• **Email collection**: cewl -e http://target.com (find email addresses)\n• **Authentication**: cewl --auth_type basic --auth_user admin --auth_pass pass http://target.com\n\n**EXAMPLE COMMAND BREAKDOWN:**\ncewl -d 2 -m 5 -w custom_wordlist.txt http://target.com\n• -d 2: Spider depth of 2 links\n• -m 5: Minimum 5 characters per word\n• -w: Write to custom_wordlist.txt\n\n**HAILEY'S ATTACK SCENARIO:**\n1. Gathered employee/client email addresses (via search engines, social media, web spidering)\n2. Used CeWL to scrape competitor's website\n3. Generated wordlist with company-specific terms\n4. Performed brute-force attack on email accounts using custom wordlist\n5. Higher success rate: Passwords often contain organization-related words\n\n**WHY CONTEXT-SPECIFIC WORDLISTS ARE EFFECTIVE:**\n• Company name + years (CompanyName2024!)\n• Product names (ProductName123)\n• Industry terminology\n• Location-based words\n• Employee names combinations\n• More targeted than generic dictionaries (rockyou.txt)\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **Orbot**: Tor proxy for Android - routes traffic through Tor network for anonymity. NOT a web scraping or wordlist tool\n• **Shadowsocks**: Encrypted SOCKS5 proxy for bypassing censorship/firewalls. Network proxy, NOT wordlist generation\n• **Psiphon**: VPN/proxy tool for circumventing internet censorship. Anonymity tool, NOT reconnaissance/wordlist tool\n\n**COMPLEMENTARY TOOLS:**\n• **John the Ripper**: Uses CeWL wordlists for password cracking\n• **Hydra**: Brute-force tool accepting custom wordlists\n• **Hashcat**: Advanced password recovery with wordlist support\n• **Mentalist**: Wordlist generator with rules\n\n**KEY CONCEPTS:**\n• Custom Wordlist Generation: Creating targeted dictionaries for attacks\n• Web Spidering: Automated website crawling for content extraction\n• Dictionary Attack: Password guessing using wordlist\n• Social Engineering Context: Using organization-specific intelligence\n• Password Psychology: Users choose familiar, memorable passwords\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Website Footprinting > Mirroring Websites > CeWL"
  },
  {
    "id": 303,
    "pdf_number": 307,
    "question": "Louis, a professional hacker, had used specialized tools or search engines to encrypt all his browsing activity and navigate anonymously to obtain sensitive/hidden information about official government or federal databases. After gathering the information, he successfully performed an attack on the target government organization without being traced. Which of the following techniques is described in the above scenario?",
    "options": [
      "Website footprinting",
      "Dark web footprinting",
      "VPN footprinting",
      "VoIP footprinting"
    ],
    "correct": [
      1
    ],
    "type": "single",
    "domain": 2,
    "explanation": "**CORRECT ANSWER: Dark web footprinting**\n\n**Dark Web Footprinting** is reconnaissance using anonymization tools to access hidden networks and gather sensitive information untraceably:\n\n**DARK WEB DEFINITION:**\n• **Dark Web**: Hidden part of internet requiring special software to access (.onion, .i2p domains)\n• **Difference from Deep Web**: Deep web = unindexed content (databases, intranets); Dark web = intentionally hidden, anonymous networks\n• **Access Requirement**: Tor browser, I2P, Freenet - NOT accessible via regular browsers\n• **Anonymity**: Multi-layer encryption, routing through relay nodes masks user identity\n\n**LOUIS'S SCENARIO - KEY INDICATORS:**\n• \"Specialized tools or search engines\" → Tor browser\n• \"Encrypt all browsing activity\" → Tor's onion routing (multi-layer encryption)\n• \"Navigate anonymously\" → Hidden IP address, untraceable traffic\n• \"Sensitive/hidden information\" → Dark web databases, leaked documents\n• \"Official government or federal databases\" → Compromised/leaked government data on dark web\n• \"Without being traced\" → Tor anonymity prevented detection\n\n**DARK WEB FOOTPRINTING TOOLS:**\n\n**1. TOR BROWSER:**\n• **Function**: Anonymizing web browser based on Firefox\n• **Technology**: Onion routing - traffic encrypted and bounced through multiple relays\n• **Access**: .onion websites (hidden services)\n• **Anonymity**: Hides user IP, location, browsing activity\n\n**2. DARK WEB SEARCH ENGINES:**\n• **Ahmia**: Clearnet search engine indexing .onion sites\n• **Torch**: Largest dark web search engine\n• **DuckDuckGo (Tor)**: Privacy-focused search via Tor\n• **Not Evil**: Uncensored onion search\n• **Haystak**: Claims 1.5B+ indexed dark web pages\n\n**3. DARK WEB INTELLIGENCE SOURCES:**\n• **Leak Databases**: Compromised government/corporate data\n• **Hacking Forums**: Exploit databases, vulnerability information\n• **Credential Markets**: Stolen usernames/passwords\n• **Document Repositories**: Classified/sensitive documents\n• **Whistleblower Platforms**: SecureDrop, leaked information\n\n**INFORMATION GATHERED FROM DARK WEB:**\n• Leaked government databases\n• Stolen credentials (government employee accounts)\n• Internal documents and classified information\n• Vulnerability databases\n• Exploit code and zero-days\n• Organizational intelligence\n• Employee personal information\n\n**DARK WEB FOOTPRINTING PROCESS:**\n1. Install Tor browser for anonymity\n2. Access dark web search engines (.onion sites)\n3. Search for target organization intelligence\n4. Download leaked databases/documents\n5. Analyze gathered information\n6. Plan attack using intelligence (Louis did this)\n7. Execute attack on target organization\n\n**WHY THE OTHERS ARE WRONG:**\n\n• **Website Footprinting**: Reconnaissance of SURFACE WEB (public websites) - uses regular browsers, NO anonymization, NOT hidden/sensitive databases. Examples: WHOIS, Google dorking, robots.txt\n• **VPN Footprinting**: Discovering VPN infrastructure (login portals, configurations, endpoints) - focuses on VPN technology, NOT dark web access or anonymity\n• **VoIP Footprinting**: Reconnaissance of Voice over IP systems (SIP servers, phone systems, PBX) - telephone technology, COMPLETELY unrelated to dark web\n\n**ANONYMITY TECHNIQUES:**\n• **Tor (The Onion Router)**: Multi-layer encryption, traffic routing through global relay network\n• **VPN + Tor**: Double anonymization (VPN → Tor → destination)\n• **Tails OS**: Amnesic operating system routing all traffic through Tor\n• **Whonix**: Virtual machine setup for Tor isolation\n\n**LEGAL & ETHICAL CONSIDERATIONS:**\n• Accessing dark web is legal (curiosity, research, privacy)\n• Illegal activities ON dark web are criminal (buying stolen data, drugs, weapons)\n• Ethical hackers may use dark web for threat intelligence\n• Law enforcement monitors dark web for criminal activity\n\n**KEY CONCEPTS:**\n• Dark Web: Hidden internet requiring special access (Tor, I2P)\n• Tor Browser: Anonymizing browser using onion routing\n• Onion Routing: Multi-layer encryption through relay nodes\n• .onion Sites: Hidden services only accessible via Tor\n• Anonymity: Untraceable browsing hiding user identity\n• Leak Databases: Stolen/compromised sensitive information\n\n**CEH REFERENCE:** Module 02 - Footprinting and Reconnaissance > Dark Web Footprinting > Tor Browser and Dark Web Search Engines"
  }
]